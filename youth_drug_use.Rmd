---
title: "Youth Drug Use"
author: "Tyler Franck"
date: "2025-04-14"
output: html_document
---

```{r}
library(tidyverse)
library(tree)
library(randomForest)
library(gbm)
```

# 1. The Data

We will explore youth drug use using a [filtered verson](https://github.com/mendible/5322/tree/main/Homework%201) of the [2023 National Survey on Drug Use and Health](https://www.samhsa.gov/data/dataset/national-survey-drug-use-and-health-2023-nsduh-2023-ds0001). Detailed documentation can be found in the codebook on the NSDUH site, but the comments in the `YouthParse.R` file are more accessible though incomplete. In summary, the data includes:

- For alcohol, marijuana, and cigarettes:
  - frequency of use over the last year/month
  - age of first use
  - have/have not used ever
  - imputed categories for drug frequency (e.g. 1-2 days, 3-5 days, 6-10 days)
- Basic demographics like sex, race, household income
- Youth-specific demographics like parental presence in the household and school attendance


```{r}
load("youth_data.Rdata")
df[1:5,]
```

```{r}
substance_cols
```

```{r}
demographic_cols
```
```{r}
youth_experience_cols
```

# 2. The Question

We are tasked with investigating the factors that correlate with youth drug usage. In particular, we will try to answer the following question: *Which demographic, behavioral, and social factors best predict _ongoing_ drug usage, and do these predictors differ for alcohol, marijuana, and cigarettes?* As per the assignment specification, we must include an example of binary classification, multi-class classification, and regression, and so we will apply each to one of alcohol, marijuana, and cigarette usage.

```{r}
df_non_substance <- cbind(df[,demographic_cols],df[,youth_experience_cols])
```

# 3. Modeling

## 3.1 Alcohol (Binary)

We want to find the predictors that best track ongoing alcohol usage, for which we will use a binary variable that indicates whether or not they've used alcohol in the past 30 days. We need to be careful to exclude "equivalent" variables from our analysis (e.g., we shouldn't try to predict binary usage with the _number of times_ they've use it).

```{r}
alcohol <- df_non_substance

# IRALCFM = 91 (never used alcohol), 93 (didn't use in past month)
alcohol[,"ALCOHOL"] <- factor(ifelse(df[,"IRALCFM"]<91,1,0))

alcohol[1:5,]
```

```{r}
set.seed(5322)

train <- sample(1:nrow(alcohol), 0.75*nrow(alcohol))
test <- -(train)
alcohol.train <- alcohol[train,]
alcohol.test <- alcohol[test,]
```

### 3.1.1 Decision Tree

```{r}
tree.alcohol <- tree(ALCOHOL ~ ., alcohol.train)
summary(tree.alcohol)
plot(tree.alcohol)
text(tree.alcohol,pretty=0)
```

The decision tree just predicting the most common response might be evidence that none of the predictors are particularly useful, though we will hold off on making this conclusion.

### 3.2.2 Bagging

The `randomForest` function doesn't work with missing values, and so we must either impute these values or drop them. For simplicity, we will just drop them, though this could bias our results.

```{r}
# effect across train and test sets should be consistent due to random sampling
alcohol.train.nna <- na.omit(alcohol.train)  # 7920 > 6213 rows
alcohol.test.nna <- na.omit(alcohol.test)    # 2641 > 2036 rows
```

```{r}
# number of predictors
p <- ncol(alcohol)-1
p
```

```{r}
set.seed(5322)

bag.alcohol <- randomForest(
  ALCOHOL ~ .,
  alcohol.train.nna,
  mtry=p,
  importance=TRUE
)
bag.alcohol
```

```{r}
# for future reference, ~100 trees is probably enough
plot(
  x=1:bag.alcohol$ntree,
  xlab="Number of Trees",
  y=bag.alcohol$err.rate[,"OOB"],
  ylab="OOB Error"
)
```

```{r}
importance(bag.alcohol)
varImpPlot(bag.alcohol)
```

```{r}
# Null model that always predicts the most common response (0: no alcohol)
mean(alcohol.test.nna$ALCOHOL==0)

# Test accuracy
pred <- predict(bag.alcohol,alcohol.test.nna,type="class")
mean(pred==alcohol.test.nna$ALCOHOL)
```

```{r}
table(pred,alcohol.test.nna$ALCOHOL)
```

That the test accuracy is higher than that produced using the null model might suggest that it is capturing _something_ in the data, but they are so close that it is hard to tell. Provisionally, we might pick out the following predictors as potentially being useful (based on importance values):
- `YFLMJMO`: How youth feels about peer marijuana usage
- `STNDALC`: Peer alcohol consumption
- `INCOME`: Family income

## 3.2 Marijuana (Multi-class)

```{r}
marijuana <- df_non_substance

# # days used in past month (0=none, 1=1-2, 2=3-5, 3=6-19, 4=20-30)
marijuana$MARIJUANA <- df$MRJMDAYS
marijuana[marijuana$MARIJUANA==5,"MARIJUANA"] <- 0
marijuana$MARIJUANA <- factor(marijuana$MARIJUANA)
marijuana[1:5,]
```

```{r}
set.seed(5322)

train <- sample(1:nrow(marijuana), 0.75*nrow(marijuana))
test <- -(train)
marijuana.train <- marijuana[train,]
marijuana.test <- marijuana[test,]
```

### 3.2.1 Decision Tree

```{r}
tree.marijuana <- tree(MARIJUANA ~ ., marijuana.train)
summary(tree.marijuana)
plot(tree.marijuana)
text(tree.marijuana,pretty=0)
```

```{r}
# Base-line
mean(marijuana.test$MARIJUANA==0)

# Test accuracy
pred <- predict(tree.marijuana,marijuana.test,type="class")
mean(pred==marijuana.test$MARIJUANA)
```

```{r}
table(pred,marijuana.test$MARIJUANA)
```

Performance is indistinguishable from base-line; we'll try pruning.

```{r}
cv.marijuana <- cv.tree(tree.marijuana)
plot(cv.marijuana$size, cv.marijuana$dev, type = "b")
```

```{r}
prune.marijuana <- prune.misclass(tree.marijuana, best = 3)
plot(prune.marijuana)
text(prune.marijuana, pretty = 0)
```

```{r}
# Base-line
mean(marijuana.test$MARIJUANA==0)

# Test accuracy
pred <- predict(prune.marijuana,marijuana.test,type="class")
mean(pred==marijuana.test$MARIJUANA)
```

```{r}
table(pred,marijuana.test$MARIJUANA)
```

Again, the performance isn't much better than the base-line, and so it is hard to be confident about and claims of correlation. However, the small advantage coming from the use of `FRDMJMON` (how close friends feel about marijuana) and `YOSELL2` (whether youth sells illegal drugs) is perhaps evidence of their meaningfulness.

### 3.2.2 Random Forest

```{r}
# effect across train and test sets should be consistent due to random sampling
marijuana.train.nna <- na.omit(marijuana.train)  # 7920 > 6213 rows
marijuana.test.nna <- na.omit(marijuana.test)    # 2641 > 2036 rows
```

```{r}
# number of predictors
p <- ncol(marijuana)-1
p
```

```{r}
set.seed(5322)

ms <- 2*(1:(p/6))  # try up to p/3 predictors (skipping by 2 for quicker compute)
accuracy <- rep(0,length(ms))
for (i in 1:length(ms)) {
  rf.marijuana.nna <- randomForest(MARIJUANA ~ ., marijuana.train.nna, mtry=ms[i])
  accuracy[i] <- mean(predict(rf.marijuana.nna,marijuana.test.nna,type="class")==marijuana.test.nna$MARIJUANA)
}
plot(
  x=ms,
  xlab="Number of Variables",
  y=accuracy,
  ylab="Test Accuracy"
)
```

```{r}
set.seed(5322)

m <- 10
rf.marijuana <- randomForest(MARIJUANA ~ ., marijuana.train.nna, mtry=m, importance=TRUE)
rf.marijuana
```

```{r}
# Null model that always predicts the most common response (0: no alcohol)
mean(marijuana.test.nna$MARIJUANA==0)

# Test accuracy
pred <- predict(rf.marijuana,marijuana.test.nna,type="class")
mean(pred==marijuana.test.nna$MARIJUANA)
```
```{r}
table(pred,marijuana.test.nna$MARIJUANA)
```

While the number of observation is very low, this model seems to be doing a decent job at predicting high marijuana usage. Of course it is still mostly guessing 0, but this is _something_.

```{r}
importance(rf.marijuana)
varImpPlot(rf.marijuana)
```

Some promising predictors are:
- `YOSELL2`: Whether youth has sold illegal drugs
- `INCOME`: Family income
- `IFATHER`: Whether father is in household
- `PRMJMO`/`PRMJEVR2`: How (youth thinks) parents would feel about them using/trying marijuana

# 3.3 Cigarette (Regression)

```{r}
cigarette <- df_non_substance

# # days used in past month
cigarette$CIGARETTE <- df$IRCIGFM
cigarette[cigarette$CIGARETTE>90,"CIGARETTE"] <- 0
cigarette[1:5,]
```

```{r}
set.seed(5322)

train <- sample(1:nrow(cigarette), 0.75*nrow(cigarette))
test <- -(train)
cigarette.train <- cigarette[train,]
cigarette.test <- cigarette[test,]
```

### 3.3.1 Decision Tree

```{r}
tree.cigarette <- tree(CIGARETTE ~ ., cigarette.train)
summary(tree.cigarette)
plot(tree.cigarette)
text(tree.cigarette,pretty=0)
```

```{r}
# Base-line
mean((cigarette.test$CIGARETTE-mean(cigarette.test$CIGARETTE))^2)

# Test accuracy
pred <- predict(tree.cigarette,cigarette.test)
mean((pred-mean(cigarette.test$CIGARETTE))^2)
1-mean((pred-mean(cigarette.test$CIGARETTE))^2)/mean((cigarette.test$CIGARETTE-mean(cigarette.test$CIGARETTE))^2)
```

It would finally seem that we've got a model that is performing significantly better than the null model!. The relevant predictors are:
- `YOSTOLE2`: Youth stole or tried to steal and item more expensive than $50
- `EDUSCHGRD2`: Current grade
- `YFLPKCG2`: How youth feels about peers smoking
- `FRDADLY2`: How youth feels about friends drinking daily

### 3.3.2 Boosting

```{r}
set.seed(5322)

B <- c(100, 500, 1000)   # number of trees
d <- c(1,2)              # interaction depth
s <- c(0.1,0.01,0.001)   # shrinkage
test.MSE <- rep(0,3*2*3)
grid <- crossing(B,d,s,test.MSE)
for (i in 1:nrow(grid)) {
  boost.cigarette <- gbm(
    CIGARETTE ~ ., cigarette.train,
    distribution="gaussian",
    n.trees=grid[i,"B"],
    interaction.depth=grid[i,"d"],
    shrinkage=grid[i,"s"],
    verbose=FALSE
  )
  pred <- predict(boost.cigarette,cigarette.test, n.trees=grid[i,]$B)
  grid[i,"test.MSE"] <- mean((pred-cigarette.test$CIGARETTE)^2)
}
grid
```

Confusingly, none of the boosted models perform anywhere close to the single decision tree, even failing to beat out the null model. Nevertheless, we might be interested in the relative influence it gives us:

```{r}
set.seed(5322)

boost.cigarette <- gbm(
  CIGARETTE ~ ., cigarette.train,
  distribution="gaussian",
  n.trees=100,
  interaction.depth=1,
  shrinkage=0.01,
  verbose=FALSE
)
summary(boost.cigarette)
```

Sharing some overlap with the decision tree, the the following predictors seem to be the most important: in order,
- `YOSTOLE2`: Youth stole or tried to steal and item more expensive than $50
- `YFLPKCG2`: How youth feels about peers smoking
- `YOSELL2`: Has youth sold illegal drugs
- `EDUSCHLGO`: Is the youth going to school
- `PRPKCIG2`: How youth thinks their parents feel about them smoking 1+ pack a day
